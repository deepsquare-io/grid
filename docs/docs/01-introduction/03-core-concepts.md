# Core concepts

## Meta-scheduling

Meta-scheduling is a technique for coordinating and optimizing the scheduling of jobs or tasks across multiple distributed computing resources. It involves using a higher-level scheduler to manage lower-level schedulers, which allocate resources and schedule jobs on individual machines or clusters.

## Infrastructure providers

Infrastructure providers are businesses or organizations that supply computing resources. They are essential in sustaining the DeepSquare Grid, offering their resources to other network participants.

As members of the DeepSquare ecosystem, these infrastructure providers may need to comply with certain prerequisites or recommendations to guarantee the security, dependability, and efficiency of the network. For instance, they might have to conform to particular hardware or software setups, perform routine updates and upkeep, and implement rigorous security measures to defend against data leaks or other hazards.

By participating in the DeepSquare grid as infrastructure providers, organizations can enjoy greater visibility to potential clients and revenue opportunities, as well as connect to an extensive network of computing resources and know-how. Simultaneously, they fulfill a vital function in promoting the continuous progress and expansion of the DeepSquare ecosystem, contributing to innovation and the advancement of distributed computing.

## High Performance Computing

High Performance Computing (HPC) employs cutting-edge hardware and software technologies to handle intricate and computationally demanding tasks. HPC systems typically consist of clusters of interconnected servers or supercomputers that collaborate to process large-scale projects.

HPC is commonly utilized in fields such as scientific research, engineering, finance, and others where massive amounts of data must be processed rapidly and accurately. Applications of HPC include weather prediction, drug development, aerospace engineering, and financial risk assessment.

HPC systems generally demand specialized hardware components like high-speed interconnects, parallel processors, and substantial amounts of memory and storage. Additionally, they depend on advanced software tools and frameworks for managing and coordinating the distribution of computational workloads throughout the cluster.

In recent times, the adoption of cloud-based HPC services has grown significantly, enabling organizations to access high-performance computing resources on-demand without investing in costly hardware or managing their own data centers. These cloud-based services often offer flexible pricing models based on usage, simplifying the process for organizations to scale their HPC capabilities as needed.

In summary, HPC is a vital and rapidly progressing field that allows researchers, scientists, and businesses to address some of the world's most complex and challenging computational issues.

## Economy of compute

"Economy of compute" refers to the concept of maximizing the use of computing resources to accomplish the greatest amount of computational tasks per unit of energy, time, or expense. In essence, it involves identifying methods to extract the highest value from available computing resources.

Several factors can influence the economy of compute, including the efficiency of hardware and software components, the complexity of algorithms and data structures, and the manner in which computational workloads are distributed across a cluster or network.

Common strategies for enhancing the economy of compute include:

- Parallelization: Dividing a large computational task into smaller, manageable segments that can be executed concurrently across multiple processors or nodes.

- Optimization: Refining algorithms, data structures, or code for a computational task to enhance its speed or efficiency.

- Resource allocation: Distributing computing resources in a way that optimizes their utilization and minimizes idle time or wasted energy.

- Cloud computing: Utilizing cloud-based services to access computing resources on-demand, enabling organizations to pay solely for the resources they require and scale up or down as needed.

By optimizing the economy of compute, organizations can achieve substantial cost savings, enhance the speed and efficiency of their computational workloads, and decrease their environmental impact by reducing energy consumption. This is especially crucial in today's data-driven economy, where the demand for computing resources is rapidly increasing, and energy costs are a significant concern.
