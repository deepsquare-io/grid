# Core concepts

## Meta-scheduling

Meta-scheduling is a technique for coordinating and optimizing the scheduling of jobs or tasks across multiple distributed computing resources. It involves using a higher-level scheduler to manage lower-level schedulers, which allocate resources and schedule jobs on individual machines or clusters.

## Infrastructure providers

Infrastructure providers are organizations or companies that provide computing resources. They play a crucial role in supporting the DeepSquare Grid, making their resources available to other users on the network.

As part of the DeepSquare ecosystem, infrastructure providers may be subject to certain requirements or guidelines to ensure the security, reliability, and performance of the network. For example, they may need to adhere to specific hardware or software configurations, provide regular updates and maintenance, and maintain strict security protocols to protect against data breaches or other threats.

By joining the DeepSquare grid as infrastructure providers, organizations can benefit from increased exposure to potential customers and revenue streams, as well as access to a wider network of computing resources and expertise. At the same time, they play a critical role in supporting the ongoing development and growth of the DeepSquare ecosystem, helping to drive innovation and advance the state of distributed computing.

## High Performance Computing

High Performance Computing (HPC) uses advanced hardware and software technologies to perform complex and computationally-intensive tasks. HPC systems often consist of clusters of interconnected servers or supercomputers that work together to execute large-scale

HPC is often used in scientific research, engineering, finance, and other fields where large amounts of data need to be processed quickly and accurately. Examples of HPC applications include weather forecasting, drug discovery, aerospace engineering, and financial risk analysis.

HPC systems typically require specialized hardware components, such as high-speed interconnects, parallel processors, and large amounts of memory and storage. They also rely on sophisticated software tools and frameworks to manage and coordinate the distribution of computational workloads across the cluster.

In recent years, the use of cloud-based HPC services has become increasingly popular, allowing organizations to access high-performance computing resources on demand without having to invest in expensive hardware or maintain their own data centers. These cloud-based services often provide flexible pricing models based on usage, making it easier for organizations to scale their HPC capabilities up or down as needed.

Overall, HPC is an important and rapidly evolving field that enables researchers, scientists, and businesses to tackle some of the world's most complex and challenging computational problems.

## Economy of compute

"Economy of compute" refers to the idea of optimizing the use of computing resources to achieve the maximum amount of computational work per unit of energy, time, or cost. In other words, it's about finding ways to get the most value out of the computing resources you have available.

There are many factors that can affect the economy of compute, such as the efficiency of hardware and software components, the complexity of algorithms and data structures, and the way that computational workloads are distributed across a cluster or network.

Some common strategies for improving the economy of compute include:

* Parallelization: Breaking up a large computational task into smaller, more manageable pieces that can be executed simultaneously across multiple processors or nodes.

* Optimization: Tweaking the algorithms, data structures, or code of a computational task to make it run faster or more efficiently.

* Resource allocation: Allocating computing resources in a way that maximizes their utilization and minimizes idle time or wasted energy.

* Cloud computing: Using cloud-based services to access computing resources on demand, allowing organizations to pay only for the resources they need and scale up or down as required.

By optimizing the economy of compute, organizations can achieve significant cost savings, improve the speed and efficiency of their computational workloads, and reduce their environmental footprint by minimizing energy usage. This is particularly important in today's data-driven economy, where the demand for computing resources is rapidly growing and the cost of energy is a major concern.
